{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"708_ELI5_data_prepare.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MMPYi3JZlbna"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92D4DbfNm2oY","outputId":"c98974f0-d30a-4de0-b554-2404d913279c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yDyrl4pqvcu","outputId":"7ded2530-7ea9-4646-c42c-fbd54338db92"},"source":["!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-43aacedb-05e5-4632-09f7-8454b76105ca)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cpJtladZnQ74"},"source":["import os\n","os.chdir('/content/drive/MyDrive/ELI5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uyUkCZtJn09X"},"source":["Install required packages and setup dataset w\\ elasticsearch-7.7.1 already in chdir"]},{"cell_type":"code","metadata":{"id":"HhZd40sZnXxq"},"source":["!pip install elasticsearch\n","!pip install faiss_gpu\n","!pip install nlp\n","!pip install transformers\n","!pip install apache_beam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOXJVCfNoEPs"},"source":["import nlp\n","eli5 = nlp.load_dataset('eli5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"POQfuHktpaRu"},"source":["eli5['test_eli5'][12345]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcoP06S_euHU"},"source":["wiki40b_snippets = nlp.load_dataset('wiki_snippets', name='wiki40b_en_100_0')['train']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYeSBT67iD_v","outputId":"2727a777-3140-4886-cc6d-c7bc9e25b831"},"source":["print(len(wiki40b_snippets))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17553713\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaYodUeNsEMP","outputId":"523bc267-87a1-4eb5-c029-c19bd1611219"},"source":["print(wiki40b_snippets[0]['passage_text'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Ági Szalóki Life She started singing as a toddler, considering Márta Sebestyén a role model. Her musical background is traditional folk music; she first won recognition for singing with Ökrös in a traditional folk style, and Besh o droM, a Balkan gypsy brass band. With these ensembles she toured around the world from the Montreal Jazz Festival, through Glastonbury Festival to the Théatre de la Ville in Paris, from New York to Beijing.\n","Since 2005, she began to pursue her solo career and explore various genres, such as jazz, thirties ballads, or children's songs.\n","Until now, three of her six released albums\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k3fQjbighNbK"},"source":["Sample around **150k** questions from this large dataset"]},{"cell_type":"code","metadata":{"id":"Y6xhEpHThMw7"},"source":["import torch\n","p_sample = 150000 / len(wiki40b_snippets)\n","masks = []\n","for i in range(len(wiki40b_snippets)):\n","  u = torch.rand(1).item()\n","  if (u < p_sample):\n","    masks.append(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMq_Q0X7izlf"},"source":["wiki40b_sub = torch.utils.data.Subset(wiki40b_snippets, masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TjVNTBXYkY8H","outputId":"2a2e1a57-490a-453f-b8ff-54fea23cb46e"},"source":["print(len(wiki40b_sub))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["150285\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmmS16y_fPRa","outputId":"12302b25-8fa0-40eb-9de6-bded55452191"},"source":["print(wiki40b_sub[0]['article_title'])\n","print(wiki40b_sub[1]['article_title'])\n","print(wiki40b_sub[2]['article_title'])\n","print(wiki40b_sub[500]['article_title'])\n","print(wiki40b_sub[-2]['article_title'])\n","print(wiki40b_sub[-1]['article_title'])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["01 Gallery\n","1633 (novel)\n","1996 Football League Third Division play-off Final\n","Robarts Centre for Canadian Studies\n","Lillian Feickert\n","Trump Tower meeting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J52_Z7YzktoU","outputId":"27887f91-eb46-4661-f2b9-a0d21018d288"},"source":["print(wiki40b_snippets[-1]['article_title'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Zychlin (Hasidic dynasty)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e770SJSX57FN"},"source":["Leverage the pretrained tokenizer and model, we start encoding questions, answers and wikis and store them."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alvJV0Ug55_n","outputId":"cef4616a-5bd0-4efe-e6f8-aae9c7921585"},"source":["from lfqa_utils import *\n","qar_tokenizer = AutoTokenizer.from_pretrained('yjernite/retribert-base-uncased')\n","qar_model = AutoModel.from_pretrained('yjernite/retribert-base-uncased').to('cuda')\n","_ = qar_model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of RetriBertModel were not initialized from the model checkpoint at yjernite/retribert-base-uncased and are newly initialized: ['bert_query.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yWyjm6KJuVbO"},"source":["wiki40b_sub.num_rows = len(wiki40b_sub)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64WV_rHA5_Cn","outputId":"8c9b9a2d-5a6e-407e-e987-36d2bd231900"},"source":["if not os.path.isfile('wiki40b_150k_reps.dat'):\n","    make_qa_dense_index(\n","        qar_model, qar_tokenizer, wiki40b_sub, device='cuda:0',\n","        index_name='wiki40b_150k_reps.dat'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["0 0.8069579601287842\n","50 42.33217978477478\n","100 91.12235140800476\n","150 150.89147639274597\n","200 213.60625791549683\n","250 278.7684471607208\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zXXebzSvz_W","outputId":"9890408c-eb51-44f5-b5eb-e3b239f7a31b"},"source":["if not os.path.isfile('wiki40b_full_reps.dat'):\n","    make_qa_dense_index(\n","        qar_model, qar_tokenizer, wiki40b_snippets, device='cuda:0',\n","        index_name='wiki40b_full_reps.dat'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["0 0.8059952259063721\n","50 40.22945737838745\n","100 79.62978672981262\n","150 119.14326071739197\n","200 158.60782766342163\n","250 198.113041639328\n","300 237.5256552696228\n","350 277.042005777359\n","400 316.4643669128418\n","450 355.9450647830963\n","500 395.2554597854614\n","550 434.6010413169861\n","600 473.91746068000793\n","650 513.2774932384491\n","700 552.8230791091919\n","750 592.1883733272552\n","800 631.5730066299438\n","850 671.1154100894928\n","900 710.4789941310883\n","950 749.8878996372223\n","1000 789.5154092311859\n","1050 829.0698997974396\n","1100 868.5392661094666\n","1150 907.9491546154022\n","1200 947.3421967029572\n","1250 986.7623460292816\n","1300 1026.2126297950745\n","1350 1065.8410556316376\n","1400 1105.2625958919525\n","1450 1144.696459054947\n","1500 1184.281000137329\n","1550 1223.76881980896\n","1600 1263.3502469062805\n","1650 1302.802945613861\n","1700 1342.4610030651093\n","1750 1381.862945318222\n","1800 1421.3493700027466\n","1850 1460.7836410999298\n","1900 1500.2021667957306\n","1950 1539.7707958221436\n","2000 1579.1695551872253\n","2050 1618.560914516449\n","2100 1658.2013466358185\n","2150 1697.7108900547028\n","2200 1737.1918849945068\n","2250 1776.8538298606873\n","2300 1816.424775838852\n","2350 1855.9130651950836\n","2400 1895.344439983368\n","2450 1934.730384349823\n","2500 1974.1351115703583\n","2550 2013.5290758609772\n","2600 2053.110344171524\n","2650 2092.476294517517\n","2700 2131.7955231666565\n","2750 2171.2733075618744\n","2800 2210.610218524933\n","2850 2250.1435265541077\n","2900 2289.5176746845245\n","2950 2328.9966955184937\n","3000 2368.314686059952\n","3050 2407.704427957535\n","3100 2447.0971372127533\n","3150 2486.4909188747406\n","3200 2526.0074684619904\n","3250 2565.354279279709\n","3300 2604.6808557510376\n","3350 2644.233859539032\n","3400 2683.604826927185\n","3450 2722.984515428543\n","3500 2762.521107673645\n","3550 2802.004102706909\n","3600 2841.3452291488647\n","3650 2880.6455376148224\n","3700 2919.8947339057922\n","3750 2959.076352596283\n","3800 2998.3307473659515\n","3850 3037.655750513077\n","3900 3076.893694639206\n","3950 3116.1703565120697\n","4000 3155.5739171504974\n","4050 3194.882354736328\n","4100 3234.368481874466\n","4150 3273.6780302524567\n","4200 3313.114280462265\n","4250 3352.387209415436\n","4300 3391.7204024791718\n","4350 3430.9771254062653\n","4400 3470.295855283737\n","4450 3509.753837585449\n","4500 3548.9895906448364\n","4550 3588.192792892456\n","4600 3627.598003387451\n","4650 3666.86713886261\n","4700 3706.132155418396\n","4750 3745.617480993271\n","4800 3785.0478105545044\n","4850 3824.275848388672\n","4900 3863.698362350464\n","4950 3902.96883225441\n","5000 3942.3256707191467\n","5050 3981.644257545471\n","5100 4020.9561059474945\n","5150 4060.209129333496\n","5200 4099.69015789032\n","5250 4139.002581357956\n","5300 4178.29752779007\n","5350 4217.731378078461\n","5400 4257.061882734299\n","5450 4296.51824760437\n","5500 4335.965950727463\n","5550 4375.220947265625\n","5600 4414.494635105133\n","5650 4453.796249866486\n","5700 4493.063526391983\n","5750 4532.307821273804\n","5800 4571.761676073074\n","5850 4611.065147161484\n","5900 4650.354310035706\n","5950 4689.803805351257\n","6000 4729.148473739624\n","6050 4768.6094670295715\n","6100 4807.96971654892\n","6150 4847.441573143005\n","6200 4886.724370002747\n","6250 4926.05476975441\n","6300 4965.365636110306\n","6350 5004.7610721588135\n","6400 5044.132153749466\n","6450 5083.670871973038\n","6500 5123.071576833725\n","6550 5162.423142194748\n","6600 5201.932661056519\n","6650 5241.370856285095\n","6700 5281.00044631958\n","6750 5320.545289039612\n","6800 5359.988395452499\n","6850 5399.573034763336\n","6900 5438.913166284561\n","6950 5478.252948522568\n","7000 5517.596145153046\n","7050 5556.99619102478\n","7100 5596.389643192291\n","7150 5635.932405233383\n","7200 5675.290727376938\n","7250 5714.664963722229\n","7300 5754.229179143906\n","7350 5793.673674583435\n","7400 5833.280689716339\n","7450 5872.826011419296\n","7500 5912.223268032074\n","7550 5951.5772886276245\n","7600 5990.97741818428\n","7650 6030.402989149094\n","7700 6069.829680919647\n","7750 6109.368022680283\n","7800 6148.752996206284\n","7850 6188.116560220718\n","7900 6227.662539482117\n","7950 6267.103834867477\n","8000 6306.649364471436\n","8050 6346.078621864319\n","8100 6385.541873931885\n","8150 6424.849103927612\n","8200 6464.153759479523\n","8250 6503.470227956772\n","8300 6542.815922260284\n","8350 6582.073760271072\n","8400 6621.542674541473\n","8450 6660.867421865463\n","8500 6700.178563833237\n","8550 6739.7053854465485\n","8600 6779.028140306473\n","8650 6818.480469465256\n","8700 6857.969552755356\n","8750 6897.344574928284\n","8800 6936.68909907341\n","8850 6975.990571737289\n","8900 7015.571170091629\n","8950 7055.003177642822\n","9000 7094.5554022789\n","9050 7133.991356134415\n","9100 7173.297941207886\n","9150 7212.775270700455\n","9200 7252.154805421829\n","9250 7291.697666883469\n","9300 7331.024049043655\n","9350 7370.47570514679\n","9400 7409.757063865662\n","9450 7449.18506360054\n","9500 7488.7085638046265\n","9550 7528.104882717133\n","9600 7567.560789823532\n","9650 7607.104768037796\n","9700 7646.5476722717285\n","9750 7686.047020196915\n","9800 7725.608142852783\n","9850 7765.071924448013\n","9900 7804.590768814087\n","9950 7844.188351392746\n","10000 7883.628239393234\n","10050 7923.079016447067\n","10100 7962.549469232559\n","10150 8001.955754041672\n","10200 8041.359937429428\n","10250 8080.912944793701\n","10300 8120.320043802261\n","10350 8159.704496622086\n","10400 8199.230412721634\n","10450 8238.657857894897\n","10500 8278.213477134705\n","10550 8317.647305250168\n","10600 8357.22078871727\n","10650 8396.62485742569\n","10700 8436.210427761078\n","10750 8475.678926229477\n","10800 8515.074781656265\n","10850 8554.543850898743\n","10900 8593.988919734955\n","10950 8633.572875261307\n","11000 8673.02896142006\n","11050 8712.480237007141\n","11100 8752.06523680687\n","11150 8791.508200645447\n","11200 8831.144597291946\n","11250 8870.675198554993\n","11300 8910.267236709595\n","11350 8949.6950340271\n","11400 8989.123065948486\n","11450 9028.667963981628\n","11500 9068.108070135117\n","11550 9107.56484413147\n","11600 9147.171658277512\n","11650 9186.591768026352\n","11700 9225.997459411621\n","11750 9265.523665428162\n","11800 9304.903300762177\n","11850 9344.438609838486\n","11900 9383.842267274857\n","11950 9423.423626422882\n","12000 9462.91281914711\n","12050 9502.25598192215\n","12100 9541.79312467575\n","12150 9581.251733541489\n","12200 9620.742278814316\n","12250 9660.099910974503\n","12300 9699.589354991913\n","12350 9738.903841733932\n","12400 9778.24095749855\n","12450 9817.77426457405\n","12500 9857.163933753967\n","12550 9896.686496019363\n","12600 9936.011683702469\n","12650 9975.49193906784\n","12700 10014.817655086517\n","12750 10054.126186609268\n","12800 10093.435609579086\n","12850 10132.737496852875\n","12900 10172.20199394226\n","12950 10211.48460149765\n","13000 10250.754279613495\n","13050 10290.213590621948\n","13100 10329.517761468887\n","13150 10368.803032636642\n","13200 10408.28331065178\n","13250 10447.776062250137\n","13300 10487.08239364624\n","13350 10526.432067871094\n","13400 10565.756402730942\n","13450 10605.108234643936\n","13500 10644.448960065842\n","13550 10683.87370300293\n","13600 10723.200374364853\n","13650 10762.510155439377\n","13700 10802.010029792786\n","13750 10841.363901376724\n","13800 10880.896250486374\n","13850 10920.209471225739\n","13900 10959.682627916336\n","13950 10999.055016040802\n","14000 11038.53573513031\n","14050 11078.044189929962\n","14100 11117.473687410355\n","14150 11156.943703889847\n","14200 11196.362604618073\n","14250 11235.688943386078\n","14300 11275.099433660507\n","14350 11314.521998167038\n","14400 11353.825116634369\n","14450 11393.266343593597\n","14500 11432.797465324402\n","14550 11472.120339155197\n","14600 11511.432182312012\n","14650 11550.748688459396\n","14700 11590.016104221344\n","14750 11629.273306131363\n","14800 11668.748072385788\n","14850 11708.053811311722\n","14900 11747.310821533203\n","14950 11786.77427649498\n","15000 11826.030288934708\n","15050 11865.433400630951\n","15100 11904.836148500443\n","15150 11944.311519145966\n","15200 11983.680518627167\n","15250 12023.027642250061\n","15300 12062.41087770462\n","15350 12101.784716129303\n","15400 12141.248296260834\n","15450 12180.497937440872\n","15500 12219.762565851212\n","15550 12259.3066136837\n","15600 12298.604677915573\n","15650 12337.905686378479\n","15700 12377.306877374649\n","15750 12416.709678173065\n","15800 12456.059552669525\n","15850 12495.352864027023\n","15900 12534.668620586395\n","15950 12573.942127466202\n","16000 12613.21759223938\n","16050 12652.691846370697\n","16100 12691.982947826385\n","16150 12731.24099612236\n","16200 12770.674903869629\n","16250 12810.021526098251\n","16300 12849.50630569458\n","16350 12888.817858934402\n","16400 12928.227914571762\n","16450 12967.550734996796\n","16500 13006.833462953568\n","16550 13046.140786886215\n","16600 13085.407297372818\n","16650 13124.823433160782\n","16700 13164.105999708176\n","16750 13203.372771263123\n","16800 13242.785247087479\n","16850 13282.091127634048\n","16900 13321.405076503754\n","16950 13360.84435582161\n","17000 13400.277421712875\n","17050 13439.550473213196\n","17100 13478.88775920868\n","17150 13518.175771713257\n","17200 13557.436677455902\n","17250 13596.760953426361\n","17300 13636.225715875626\n","17350 13675.550344944\n","17400 13714.846884012222\n","17450 13754.289119243622\n","17500 13793.563752651215\n","17550 13833.002160072327\n","17600 13872.354523181915\n","17650 13911.7895257473\n","17700 13951.062784910202\n","17750 13990.338782548904\n","17800 14029.646325349808\n","17850 14068.896143198013\n","17900 14108.379561185837\n","17950 14147.73742389679\n","18000 14187.007233858109\n","18050 14226.60329246521\n","18100 14266.142382383347\n","18150 14305.560056209564\n","18200 14345.13670539856\n","18250 14384.738875865936\n","18300 14424.221801996231\n","18350 14463.520877361298\n","18400 14502.880534410477\n","18450 14542.295688390732\n","18500 14581.72781085968\n","18550 14621.328051805496\n","18600 14660.837598323822\n","18650 14700.286497354507\n","18700 14739.905267715454\n","18750 14779.372252464294\n","18800 14818.93000125885\n","18850 14858.536988019943\n","18900 14898.383663892746\n","18950 14937.982986211777\n","19000 14977.539828062057\n","19050 15017.12674331665\n","19100 15056.63023018837\n","19150 15096.286612510681\n","19200 15135.733105897903\n","19250 15175.31491112709\n","19300 15214.919564723969\n","19350 15254.555676698685\n","19400 15293.932144403458\n","19450 15333.451644182205\n","19500 15372.965765476227\n","19550 15412.360053062439\n","19600 15451.779589653015\n","19650 15491.269814014435\n","19700 15530.903038740158\n","19750 15570.39168381691\n","19800 15610.071346282959\n","19850 15649.68428516388\n","19900 15689.276332378387\n","19950 15729.022433280945\n","20000 15768.664386987686\n","20050 15808.445746421814\n","20100 15848.174067497253\n","20150 15888.02615571022\n","20200 15927.649122714996\n","20250 15967.195093154907\n","20300 16006.688402175903\n","20350 16046.133873939514\n","20400 16085.703196525574\n","20450 16125.144021987915\n","20500 16164.50880599022\n","20550 16203.895452976227\n","20600 16243.44644498825\n","20650 16282.859822034836\n","20700 16322.404432535172\n","20750 16361.92938041687\n","20800 16401.324110507965\n","20850 16440.69136595726\n","20900 16480.0893535614\n","20950 16519.52381515503\n","21000 16558.95662331581\n","21050 16598.474678754807\n","21100 16637.852546453476\n","21150 16677.18190264702\n","21200 16716.68333363533\n","21250 16756.045169591904\n","21300 16795.538902759552\n","21350 16834.9126765728\n","21400 16874.47539663315\n","21450 16913.83865261078\n","21500 16953.26754426956\n","21550 16992.69817018509\n","21600 17032.169517040253\n","21650 17071.90124487877\n","21700 17111.462565422058\n","21750 17150.888370275497\n","21800 17190.35504102707\n","21850 17230.011820316315\n","21900 17269.433533906937\n","21950 17309.062633275986\n","22000 17348.734174489975\n","22050 17388.189730644226\n","22100 17427.656773090363\n","22150 17467.151076078415\n","22200 17506.580763816833\n","22250 17546.06322312355\n","22300 17585.705286502838\n","22350 17625.148778676987\n","22400 17664.622454166412\n","22450 17704.252183437347\n","22500 17743.771922826767\n","22550 17783.44561624527\n","22600 17822.929265737534\n","22650 17862.576377153397\n","22700 17902.035215616226\n","22750 17941.541443824768\n","22800 17980.919314146042\n","22850 18020.28996682167\n","22900 18059.846647024155\n","22950 18099.23964691162\n","23000 18138.658520936966\n","23050 18178.05609512329\n","23100 18217.565861225128\n","23150 18256.947308301926\n","23200 18296.65751004219\n","23250 18336.313303232193\n","23300 18375.82381439209\n","23350 18415.30995297432\n","23400 18454.798934698105\n","23450 18494.281002283096\n","23500 18533.78231573105\n","23550 18573.400484085083\n","23600 18612.94614672661\n","23650 18652.44465470314\n","23700 18692.131601333618\n","23750 18731.701632261276\n","23800 18771.295746564865\n","23850 18810.80754494667\n","23900 18850.451986789703\n","23950 18889.993381261826\n","24000 18929.518800973892\n","24050 18968.989480257034\n","24100 19008.471777439117\n","24150 19048.06596660614\n","24200 19087.441210269928\n","24250 19126.941014528275\n","24300 19166.42186808586\n","24350 19206.078668117523\n","24400 19245.580149173737\n","24450 19285.206433296204\n","24500 19324.875873088837\n","24550 19364.355283260345\n","24600 19403.80487060547\n","24650 19443.237425088882\n","24700 19482.708687782288\n","24750 19522.216775417328\n","24800 19561.826635837555\n","24850 19601.272373199463\n","24900 19640.75519323349\n","24950 19680.43753385544\n","25000 19719.977344751358\n","25050 19759.651005983353\n","25100 19799.176035165787\n","25150 19838.85602736473\n","25200 19878.32243990898\n","25250 19917.830858945847\n","25300 19957.32914710045\n","25350 19996.858533382416\n","25400 20036.5070168972\n","25450 20076.029953956604\n","25500 20115.52406001091\n","25550 20154.99638724327\n","25600 20194.66763472557\n","25650 20234.14022064209\n","25700 20273.838629722595\n","25750 20313.57389855385\n","25800 20353.114352226257\n","25850 20392.816170930862\n","25900 20432.360411167145\n","25950 20471.878267765045\n","26000 20511.421984434128\n","26050 20550.941556215286\n","26100 20590.438593387604\n","26150 20630.129446029663\n","26200 20669.62252521515\n","26250 20709.167580366135\n","26300 20748.8260576725\n","26350 20788.33738732338\n","26400 20827.977641105652\n","26450 20867.642149925232\n","26500 20907.148055791855\n","26550 20946.662625074387\n","26600 20986.141005516052\n","26650 21025.603175640106\n","26700 21065.062455654144\n","26750 21104.800328731537\n","26800 21144.318389177322\n","26850 21183.81587934494\n","26900 21223.51094007492\n","26950 21263.00878429413\n","27000 21302.675597906113\n","27050 21342.184300661087\n","27100 21381.82023024559\n","27150 21421.325525522232\n","27200 21460.823882579803\n","27250 21500.286380767822\n","27300 21539.78704071045\n","27350 21579.27742123604\n","27400 21618.939322710037\n","27450 21658.477242946625\n","27500 21698.053663253784\n","27550 21737.735894441605\n","27600 21777.259746074677\n","27650 21816.98661160469\n","27700 21856.70182943344\n","27750 21896.23838019371\n","27800 21935.99195408821\n","27850 21975.575820446014\n","27900 22015.30565237999\n","27950 22054.80619072914\n","28000 22094.331048965454\n","28050 22133.915937900543\n","28100 22173.407195091248\n","28150 22213.094448804855\n","28200 22252.643431425095\n","28250 22292.24257349968\n","28300 22331.944765090942\n","28350 22371.49464726448\n","28400 22411.203022241592\n","28450 22450.788693666458\n","28500 22490.484454393387\n","28550 22530.063412427902\n","28600 22569.589190483093\n","28650 22609.105383634567\n","28700 22648.63769364357\n","28750 22688.184675216675\n","28800 22727.89468383789\n","28850 22767.46640896797\n","28900 22807.028714179993\n","28950 22846.76866197586\n","29000 22886.288001060486\n","29050 22926.05199289322\n","29100 22965.600175857544\n","29150 23005.316426992416\n","29200 23044.85029387474\n","29250 23084.360800504684\n","29300 23123.891466856003\n","29350 23163.35961985588\n","29400 23202.984503507614\n","29450 23242.54075360298\n","29500 23282.19156885147\n","29550 23321.901918172836\n","29600 23361.470270633698\n","29650 23401.20420408249\n","29700 23440.755573272705\n","29750 23480.482848405838\n","29800 23520.027859449387\n","29850 23559.568620681763\n","29900 23599.107717990875\n","29950 23638.611804246902\n","30000 23678.1481590271\n","30050 23717.820945739746\n","30100 23757.385763406754\n","30150 23796.961205005646\n","30200 23836.69814491272\n","30250 23876.16368484497\n","30300 23915.749923944473\n","30350 23955.26706790924\n","30400 23994.806188821793\n","30450 24034.401851654053\n","30500 24073.962505817413\n","30550 24113.385905981064\n","30600 24152.83150625229\n","30650 24192.25002670288\n","30700 24231.653292179108\n","30750 24271.210837841034\n","30800 24310.669667720795\n","30850 24350.107320308685\n","30900 24389.711862802505\n","30950 24429.086030483246\n","31000 24468.633334875107\n","31050 24508.10591506958\n","31100 24547.70881128311\n","31150 24587.12143087387\n","31200 24626.51521205902\n","31250 24665.88525080681\n","31300 24705.17075586319\n","31350 24744.483649015427\n","31400 24783.684735774994\n","31450 24822.908567905426\n","31500 24862.108726978302\n","31550 24901.42568421364\n","31600 24940.629654169083\n","31650 24980.051505565643\n","31700 25019.579586029053\n","31750 25058.897991895676\n","31800 25098.19576239586\n","31850 25137.528052568436\n","31900 25176.872867822647\n","31950 25216.203491687775\n","32000 25255.688043117523\n","32050 25295.081445217133\n","32100 25334.41608262062\n","32150 25373.81399655342\n","32200 25413.111038923264\n","32250 25452.487548351288\n","32300 25491.751333236694\n","32350 25531.174273729324\n","32400 25570.394680023193\n","32450 25609.665730953217\n","32500 25648.88702058792\n","32550 25688.13791179657\n","32600 25727.398885011673\n","32650 25766.79122710228\n","32700 25805.96703672409\n","32750 25845.058957338333\n","32800 25884.31413292885\n","32850 25923.357540130615\n","32900 25962.527333021164\n","32950 26001.636465072632\n","33000 26040.72358417511\n","33050 26079.82172179222\n","33100 26119.016280651093\n","33150 26158.210802078247\n","33200 26197.404101133347\n","33250 26236.75032734871\n","33300 26275.99105000496\n","33350 26315.20012974739\n","33400 26354.640545606613\n","33450 26393.93941307068\n","33500 26433.434259176254\n","33550 26472.848717451096\n","33600 26512.436227798462\n","33650 26552.018802642822\n","33700 26591.28816127777\n","33750 26630.627214431763\n","33800 26670.074601650238\n","33850 26709.4783577919\n","33900 26748.99191570282\n","33950 26788.63719558716\n","34000 26828.15169930458\n","34050 26867.689311504364\n","34100 26907.34903717041\n","34150 26946.853777885437\n","34200 26986.4584107399\n","34250 27025.99210548401\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vifadfr0f8ft"},"source":["Get a even samller 30K documents."]},{"cell_type":"code","metadata":{"id":"Rc2ccfCqX167"},"source":["import torch\n","p_sample = 30000 / len(wiki40b_snippets)\n","tk_masks = []\n","for i in range(len(wiki40b_snippets)):\n","  u = torch.rand(1).item()\n","  if (u < p_sample):\n","    tk_masks.append(i)\n","wiki30k = torch.utils.data.Subset(wiki40b_snippets, tk_masks)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOa5vT0KYsvP","outputId":"106af35a-202b-4bf0-fc59-ee59b25206fa"},"source":["wiki30k.num_rows = len(wiki30k)\n","if not os.path.isfile('wiki40b_30k_reps.dat'):\n","    make_qa_dense_index(\n","        qar_model, qar_tokenizer, wiki30k, device='cuda:0',\n","        index_name='wiki40b_30k_reps.dat'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["0 2.5083694458007812\n","50 105.43386363983154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-va3nilDZjl4","outputId":"99208ddc-2d40-42bf-980e-fd1a7fe5b10f"},"source":["print(wiki30k[0].keys())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['_id', 'article_title', 'end_character', 'end_paragraph', 'nlp_id', 'passage_text', 'section_title', 'start_character', 'start_paragraph', 'wiki_id'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vhYjhygGgARf"},"source":["Save dataset, and ids used to generate this subdataset."]},{"cell_type":"code","metadata":{"id":"ck4eqjSFZ1HU"},"source":["import pickle as pkl\n","def save_data(data_path, out_path):\n","  with open(out_path, 'wb') as fout:\n","    pkl.dump(data_path, fout)\n","save_data(wiki30k, \"wiki30k_dataset.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4riSXxQkfqR"},"source":["save_data(wiki40b_sub, \"wiki150k_dataset.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ur0Ms7vwdHrN"},"source":["test = pkl.load(open(\"wiki30k_dataset.pkl\",\"rb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CsIwVnWvd-U9","outputId":"9f93c5d8-9fe9-4f13-c557-7e6d97efb653"},"source":["print(len(test))\n","print(wiki30k.num_rows)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29727\n","29727\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qld0_mhZhFhn"},"source":["Save sampled id-array"]},{"cell_type":"code","metadata":{"id":"qOR0toKQeC5J"},"source":["import numpy as np\n","def save_ids(path, arr):\n","  with open(path, \"wb\") as f:\n","    np.save(f, np.array(arr))\n","\n","def load_ids(path):\n","  with open(path, \"rb\") as f:\n","    ids = np.load(f)\n","  return ids"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqaNDeRuhcP1"},"source":["save_ids(\"ids_for_30k.npy\", tk_masks)\n","save_ids(\"ids_for_150k.npy\", masks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yqN-L-2XgGH4"},"source":["Save 20 / 200 / 2000 questions and their embeddings."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"TupAKZ6ffggQ","outputId":"f1ebcbbf-6bbd-43df-e0bb-0c9beac7831c"},"source":["eli5['test_eli5'][12345]['title']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Why does water heated to room temperature feel colder than the air around it?'"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0e-coY67fmGZ","outputId":"5ac7de00-2e05-467b-a8e5-79a019c4f600"},"source":["len(eli5['test_eli5'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24512"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"AOMVE-vzgTKR"},"source":["def sampler(sample_num, total_size):\n","  p_sample = sample_num / total_size\n","  sample_id = []\n","  for i in range(total_size):\n","    u = torch.rand(1).item()\n","    if (u < p_sample):\n","      sample_id.append(i)\n","  return sample_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2e3Ho32gtYW"},"source":["q_total_size = len(eli5['test_eli5'])\n","q_20_ids = sampler(20, q_total_size)\n","q_200_ids = sampler(200, q_total_size)\n","q_2000_ids = sampler(200, q_total_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uT65cZBdhhgm"},"source":["save_ids(\"ids_for_q_20.npy\", q_20_ids)\n","save_ids(\"ids_for_q_200.npy\", q_200_ids)\n","save_ids(\"ids_for_q_2000.npy\", q_2000_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LZpEdQcjLAu"},"source":["def save_ques(q_ids, path):  \n","  q = []\n","  for id in q_ids:\n","    q.append(eli5['test_eli5'][id]['title'])\n","  with open(path, \"w\") as f:\n","    f.write(\"\\n\".join(q))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-kWNwLCjkq2"},"source":["save_ques(q_20_ids, \"question_20_text.tsv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwT9zO6wjvXl"},"source":["save_ques(q_200_ids, \"question_200_text.tsv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfTE9lg-jwTf"},"source":["save_ques(q_2000_ids, \"question_2000_text.tsv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kwiJXk-Lh-ZF"},"source":["save questions representation"]},{"cell_type":"code","metadata":{"id":"WWQTWjX-hs8-"},"source":["def save_q_rep(path, q_ids):\n","  rep = np.zeros((len(q_ids), 128))\n","  idx = 0\n","  for id in q_ids:\n","    q = eli5['test_eli5'][id]['title']\n","    q_rep = embed_questions_for_retrieval([q], qar_tokenizer, qar_model)\n","    rep[idx] = q_rep\n","    idx += 1\n","  save_ids(path, rep)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbIEJjjeizC6","outputId":"be44baab-8980-4310-bd7e-c63098efbeee"},"source":["save_q_rep(\"q_20_reps.npy\", q_20_ids)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01dx27JAi-Uj","outputId":"ce9dafbd-4144-42d8-f022-8737016ab140"},"source":["save_q_rep(\"q_200_reps.npy\", q_200_ids)\n","save_q_rep(\"q_2000_reps.npy\", q_2000_ids)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qh-ya38F6L1D"},"source":["Retrieving wiki based on embeddings."]},{"cell_type":"code","metadata":{"id":"lCGG7tTF6CkE"},"source":["faiss_res = faiss.StandardGpuResources()\n","wiki40b_passage_reps = np.memmap(\n","            'wiki40b_.dat',\n","            dtype='float32', mode='r',\n","            shape=(wiki40b_snippets.num_rows, 128)\n",")\n","\n","wiki40b_index_flat = faiss.IndexFlatIP(128)\n","wiki40b_gpu_index = faiss.index_cpu_to_gpu(faiss_res, 1, wiki40b_index_flat)\n","wiki40b_gpu_index.add(wiki40b_passage_reps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFn7k80H6IgK"},"source":["question = eli5['test_eli5'][12345]['title']\n","doc, res_list = query_qa_dense_index(question, qar_model, qar_tokenizer, wiki40b_snippets, wiki40b_gpu_index, device='cuda:1')\n","\n","df = pd.DataFrame({\n","    'Article': ['---'] + [res['article_title'] for res in res_list],\n","    'Sections': ['---'] + [res['section_title'] if res['section_title'].strip() != '' else res['article_title']\n","                 for res in res_list],\n","    'Text': ['--- ' + question] + [res['passage_text'] for res in res_list],\n","})\n","df.style.set_properties(**{'text-align': 'left'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dyL9uzYYf5qk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOTaBO9R6JiR"},"source":["test_qa_list = [(exple['title'],\n","                ' '.join([a \n","                          for i, (a, sc) in enumerate(zip(exple['answers']['text'], exple['answers']['score'])) \\\n","                          if i == 0 or sc >= 3\n","                         ]))\n","                for exple in eli5['test_eli5']]\n","\n","# We then compute word frequencies in answer text\n","answer_doc_freq = {}\n","for q, a in test_qa_list:\n","    for w in a.lower().split():\n","        answer_doc_freq[w] = answer_doc_freq.get(w, 0) + 1\n","\n","# The IDF-recall function is then:\n","def da_idf_recall(doc, answer):\n","    d_words = dict([(w, True) for w in doc.lower().split()])\n","    a_words = answer.lower().split()   \n","    recall = sum([1. / math.log(1 + answer_doc_freq.get(w, 1)) for w in a_words if w in d_words]) / \\\n","                sum([1. / math.log(1 + answer_doc_freq.get(w, 1)) for w in a_words])\n","    return recall"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLFCMY2F6Kd4"},"source":["\n","def dense_ret_for_eval(question, n_ret):\n","    _, dense_res_list = query_qa_dense_index(\n","        question, qar_model, qar_tokenizer, wiki40b_snippets, wiki40b_gpu_index, n_results=n_ret, device='cuda:1'\n","    )\n","    dense_doc = ' '.join([res['passage_text'] for res in dense_res_list])\n","    return dense_doc\n","\n","def sparse_ret_for_eval(question, n_ret):\n","    _, sparse_res_list = query_es_index(\n","        question, es_client, index_name='wiki40b_snippets_100w', n_results=n_ret\n","    )\n","    sparse_doc = ' '.join([res['passage_text'] for res in sparse_res_list])\n","    return sparse_doc\n","\n","dense_score = evaluate_retriever(test_qa_list, dense_ret_for_eval, da_idf_recall)\n","sparse_score = evaluate_retriever(test_qa_list, sparse_ret_for_eval, da_idf_recall)\n","\n","df = pd.DataFrame({\n","    'IDF-Recall': [sparse_score['idf_recall'], dense_score['idf_recall']],\n","    'Time/Query': [sparse_score['retrieval_time'], dense_score['retrieval_time']],\n","}, index=[ 'Sparse', 'Dense'])\n","df.style.format({'IDF-Recall': \"{:.4f}\", 'Time/Query': \"{:.4f}\"})"],"execution_count":null,"outputs":[]}]}