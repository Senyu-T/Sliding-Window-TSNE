{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"708_ELI5_IR.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92D4DbfNm2oY","outputId":"c98974f0-d30a-4de0-b554-2404d913279c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yDyrl4pqvcu","outputId":"7ded2530-7ea9-4646-c42c-fbd54338db92"},"source":["!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-43aacedb-05e5-4632-09f7-8454b76105ca)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cpJtladZnQ74"},"source":["import os\n","os.chdir('/content/drive/MyDrive/ELI5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uyUkCZtJn09X"},"source":["Install required packages and setup dataset w\\ elasticsearch-7.7.1 already in chdir"]},{"cell_type":"code","metadata":{"id":"HhZd40sZnXxq"},"source":["!pip install elasticsearch\n","!pip install faiss_gpu\n","!pip install nlp\n","!pip install transformers\n","!pip install apache_beam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOXJVCfNoEPs"},"source":["import nlp\n","eli5 = nlp.load_dataset('eli5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"POQfuHktpaRu"},"source":["eli5['test_eli5'][12345]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcoP06S_euHU"},"source":["wiki40b_snippets = nlp.load_dataset('wiki_snippets', name='wiki40b_en_100_0')['train']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYeSBT67iD_v","outputId":"2727a777-3140-4886-cc6d-c7bc9e25b831"},"source":["print(len(wiki40b_snippets))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17553713\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaYodUeNsEMP","outputId":"523bc267-87a1-4eb5-c029-c19bd1611219"},"source":["print(wiki40b_snippets[0]['passage_text'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Ági Szalóki Life She started singing as a toddler, considering Márta Sebestyén a role model. Her musical background is traditional folk music; she first won recognition for singing with Ökrös in a traditional folk style, and Besh o droM, a Balkan gypsy brass band. With these ensembles she toured around the world from the Montreal Jazz Festival, through Glastonbury Festival to the Théatre de la Ville in Paris, from New York to Beijing.\n","Since 2005, she began to pursue her solo career and explore various genres, such as jazz, thirties ballads, or children's songs.\n","Until now, three of her six released albums\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k3fQjbighNbK"},"source":["Sample around **150k** questions from this large dataset"]},{"cell_type":"code","metadata":{"id":"Y6xhEpHThMw7"},"source":["import torch\n","p_sample = 150000 / len(wiki40b_snippets)\n","masks = []\n","for i in range(len(wiki40b_snippets)):\n","  u = torch.rand(1).item()\n","  if (u < p_sample):\n","    masks.append(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMq_Q0X7izlf"},"source":["wiki40b_sub = torch.utils.data.Subset(wiki40b_snippets, masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TjVNTBXYkY8H","outputId":"2a2e1a57-490a-453f-b8ff-54fea23cb46e"},"source":["print(len(wiki40b_sub))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["150285\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmmS16y_fPRa","outputId":"12302b25-8fa0-40eb-9de6-bded55452191"},"source":["print(wiki40b_sub[0]['article_title'])\n","print(wiki40b_sub[1]['article_title'])\n","print(wiki40b_sub[2]['article_title'])\n","print(wiki40b_sub[500]['article_title'])\n","print(wiki40b_sub[-2]['article_title'])\n","print(wiki40b_sub[-1]['article_title'])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["01 Gallery\n","1633 (novel)\n","1996 Football League Third Division play-off Final\n","Robarts Centre for Canadian Studies\n","Lillian Feickert\n","Trump Tower meeting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J52_Z7YzktoU","outputId":"27887f91-eb46-4661-f2b9-a0d21018d288"},"source":["print(wiki40b_snippets[-1]['article_title'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Zychlin (Hasidic dynasty)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e770SJSX57FN"},"source":["Leverage the pretrained tokenizer and model, we start encoding questions, answers and wikis and store them."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alvJV0Ug55_n","outputId":"cef4616a-5bd0-4efe-e6f8-aae9c7921585"},"source":["from lfqa_utils import *\n","qar_tokenizer = AutoTokenizer.from_pretrained('yjernite/retribert-base-uncased')\n","qar_model = AutoModel.from_pretrained('yjernite/retribert-base-uncased').to('cuda')\n","_ = qar_model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of RetriBertModel were not initialized from the model checkpoint at yjernite/retribert-base-uncased and are newly initialized: ['bert_query.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yWyjm6KJuVbO"},"source":["wiki40b_sub.num_rows = len(wiki40b_sub)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64WV_rHA5_Cn","outputId":"8c9b9a2d-5a6e-407e-e987-36d2bd231900"},"source":["if not os.path.isfile('wiki40b_150k_reps.dat'):\n","    make_qa_dense_index(\n","        qar_model, qar_tokenizer, wiki40b_sub, device='cuda:0',\n","        index_name='wiki40b_150k_reps.dat'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["0 0.8069579601287842\n","50 42.33217978477478\n","100 91.12235140800476\n","150 150.89147639274597\n","200 213.60625791549683\n","250 278.7684471607208\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zXXebzSvz_W","outputId":"9890408c-eb51-44f5-b5eb-e3b239f7a31b"},"source":["if not os.path.isfile('wiki40b_full_reps.dat'):\n","    make_qa_dense_index(\n","        qar_model, qar_tokenizer, wiki40b_snippets, device='cuda:0',\n","        index_name='wiki40b_full_reps.dat'\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["0 0.8059952259063721\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qh-ya38F6L1D"},"source":["Retrieving wiki based on embeddings."]},{"cell_type":"code","metadata":{"id":"lCGG7tTF6CkE"},"source":["faiss_res = faiss.StandardGpuResources()A'''  '''\n","wiki40b_passage_reps = np.memmap(\n","            'wiki40b_passages_reps_32_l-8_h-768_b-512-512.dat',\n","            dtype='float32', mode='r',\n","            shape=(wiki40b_snippets.num_rows, 128)\n",")\n","\n","wiki40b_index_flat = faiss.IndexFlatIP(128)\n","wiki40b_gpu_index = faiss.index_cpu_to_gpu(faiss_res, 1, wiki40b_index_flat)\n","wiki40b_gpu_index.add(wiki40b_passage_reps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFn7k80H6IgK"},"source":["question = eli5['test_eli5'][12345]['title']\n","doc, res_list = query_qa_dense_index(question, qar_model, qar_tokenizer, wiki40b_snippets, wiki40b_gpu_index, device='cuda:1')\n","\n","df = pd.DataFrame({\n","    'Article': ['---'] + [res['article_title'] for res in res_list],\n","    'Sections': ['---'] + [res['section_title'] if res['section_title'].strip() != '' else res['article_title']\n","                 for res in res_list],\n","    'Text': ['--- ' + question] + [res['passage_text'] for res in res_list],\n","})\n","df.style.set_properties(**{'text-align': 'left'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOTaBO9R6JiR"},"source":["test_qa_list = [(exple['title'],\n","                ' '.join([a \n","                          for i, (a, sc) in enumerate(zip(exple['answers']['text'], exple['answers']['score'])) \\\n","                          if i == 0 or sc >= 3\n","                         ]))\n","                for exple in eli5['test_eli5']]\n","\n","# We then compute word frequencies in answer text\n","answer_doc_freq = {}\n","for q, a in test_qa_list:\n","    for w in a.lower().split():\n","        answer_doc_freq[w] = answer_doc_freq.get(w, 0) + 1\n","\n","# The IDF-recall function is then:\n","def da_idf_recall(doc, answer):\n","    d_words = dict([(w, True) for w in doc.lower().split()])\n","    a_words = answer.lower().split()   \n","    recall = sum([1. / math.log(1 + answer_doc_freq.get(w, 1)) for w in a_words if w in d_words]) / \\\n","                sum([1. / math.log(1 + answer_doc_freq.get(w, 1)) for w in a_words])\n","    return recall"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLFCMY2F6Kd4"},"source":["\n","def dense_ret_for_eval(question, n_ret):\n","    _, dense_res_list = query_qa_dense_index(\n","        question, qar_model, qar_tokenizer, wiki40b_snippets, wiki40b_gpu_index, n_results=n_ret, device='cuda:1'\n","    )\n","    dense_doc = ' '.join([res['passage_text'] for res in dense_res_list])\n","    return dense_doc\n","\n","# def sparse_ret_for_eval(question, n_ret):\n","#     _, sparse_res_list = query_es_index(\n","#         question, es_client, index_name='wiki40b_snippets_100w', n_results=n_ret\n","#     )\n","#     sparse_doc = ' '.join([res['passage_text'] for res in sparse_res_list])\n","#     return sparse_doc\n","\n","dense_score = evaluate_retriever(test_qa_list, dense_ret_for_eval, da_idf_recall)\n","sparse_score = evaluate_retriever(test_qa_list, sparse_ret_for_eval, da_idf_recall)\n","\n","df = pd.DataFrame({\n","    'IDF-Recall': [sparse_score['idf_recall'], dense_score['idf_recall']],\n","    'Time/Query': [sparse_score['retrieval_time'], dense_score['retrieval_time']],\n","}, index=[ 'Sparse', 'Dense'])\n","df.style.format({'IDF-Recall': \"{:.4f}\", 'Time/Query': \"{:.4f}\"})"],"execution_count":null,"outputs":[]}]}